from .db import db

from langchain.prompts import PromptTemplate
from langchain_core.output_parsers import StrOutputParser
from langchain_core.runnables import RunnablePassthrough
from langchain_google_genai import ChatGoogleGenerativeAI
from dotenv import load_dotenv

load_dotenv()

class RAGAgent_st:
    def __init__(self):
        retriever = db.vectorstore.as_retriever(search_kwargs={"k": 5})
        template = """
        ë„ˆëŠ” ì…ë ¥ëœ ê¸ˆìœµ ë¶„ì•¼ ë‹¨ì–´ë¥¼ ì‰½ê³ , ì¼ìƒì ì¸ ì–¸ì–´ë¡œ ì„¤ëª…í•´ì£¼ëŠ” ì±—ë´‡ ì–´ì‹œìŠ¤í„´íŠ¸ì•¼.
        ê¸ˆìœµ ì§€ì‹ì´ ë¶€ì¡±í•œ ì‚¬ëŒë“¤ë„ ì‰½ê²Œ ì´í•´í•  ìˆ˜ ìˆê²Œ ì„¤ëª…í•´ì¤˜. ëª¨ë“  ëŒ€ë‹µì€ í•œêµ­ì–´ë¡œ í•´ì£¼ê³ ,
        ì–´ë ¤ìš´ ë‹¨ì–´ëŠ” ìµœëŒ€í•œ í’€ì–´ì„œ ë§í•´ì¤˜. ë¬¸ì¥ì€ ì¹œê·¼í•œ êµ¬ì–´ì²´ë¡œ ëë‚´ëŠ” ê²Œ ì¢‹ì•„.

        ê´€ë ¨ ì •ë³´ : {context}
        ë‹¨ì–´ : {term}

        ë‹¨ì–´ì˜ ì˜ë¯¸, í™œìš© ì˜ˆì‹œ, ì—°ê´€ëœ ë‹¨ì–´ 3ê°œë¥¼ ì œê³µí•´ì•¼ í•´. í˜•ì‹ì€ ì•„ë˜ì™€ ê°™ì•„:

        ğŸ’¡**ìš©ì–´ ì„¤ëª…** : 
        [ë‹¨ì–´ì˜ ì˜ë¯¸ë¥¼ ê°„ê²°í•˜ê³  ëª…í™•í•˜ê²Œ ì„¤ëª…í•´ì¤˜, 200ì ì´í•˜ë¡œ, ë¬¸ì¥ë§ˆë‹¤ ì¤„ë°”ê¿ˆì„ ì¶”ê°€í•´ì„œ ì½ê¸° ì‰½ê²Œ í•´ì¤˜] 
        ğŸ’š**í™œìš© ì˜ˆì‹œ** : 
        [ë‹¨ì–´ ì´í•´ë¥¼ ë„ì™€ì£¼ëŠ” ê°„ë‹¨í•œ ì˜ˆì‹œë¥¼ ì œì‹œí•´ì¤˜, ë¬¸ì¥ë§ˆë‹¤ ì¤„ë°”ê¿ˆì„ ì¶”ê°€í•´ì„œ ì½ê¸° ì‰½ê²Œ í•´ì¤˜]
        ğŸ”**ì—°ê´€ ë‹¨ì–´** : 
        [ë‹¨ì–´ì™€ ê´€ë ¨ ìˆëŠ” ë‹¤ë¥¸ ë‹¨ì–´ 3ê°œë¥¼ ì‰¼í‘œë¡œ êµ¬ë¶„í•´ì„œ ë‚˜ì—´]  
        """
        prompt = PromptTemplate(input_variables=["context", "term"], template=template)

        llm = ChatGoogleGenerativeAI(model="gemini-1.5-flash")
        self.chain = (
            {
                "context": retriever | self.format_retriever_output,
                "term": RunnablePassthrough(),
            }
            | prompt
            | llm 
            | StrOutputParser()
        )
    def format_retriever_output(self, docs):
        return "\n".join([doc.page_content for doc in docs])
        
    def invoke(self, user_input):
        return self.chain.invoke(user_input)
    
    def stream(self, user_input):
        return self.chain.stream(user_input)


class RAGAgent_ce:
    def __init__(self):
        retriever = db.vectorstore.as_retriever(search_kwargs={"k": 5})
        template = """
        ë„ˆëŠ” ì…ë ¥ëœ ê¸ˆìœµ ë¶„ì•¼ ë‹¨ì–´ë¥¼ ì‰½ê³ , ì¼ìƒì ì¸ ì–¸ì–´ë¡œ ì„¤ëª…í•´ì£¼ëŠ” ì±—ë´‡ ì–´ì‹œìŠ¤í„´íŠ¸ì•¼.
        ê¸ˆìœµ ì§€ì‹ì´ ë¶€ì¡±í•œ ì‚¬ëŒë“¤ë„ ì‰½ê²Œ ì´í•´í•  ìˆ˜ ìˆê²Œ ì„¤ëª…í•´ì¤˜. ëª¨ë“  ëŒ€ë‹µì€ í•œêµ­ì–´ë¡œ í•´ì£¼ê³ ,
        ì–´ë ¤ìš´ ë‹¨ì–´ëŠ” ìµœëŒ€í•œ í’€ì–´ì„œ ë§í•´ì¤˜. ë¬¸ì¥ì€ ì¹œê·¼í•œ êµ¬ì–´ì²´ë¡œ ëë‚´ëŠ” ê²Œ ì¢‹ì•„.

        ê´€ë ¨ ì •ë³´:
        {context}

        ê¸ˆìœµ ìš©ì–´: 
        {term}

        <hr>
        <h3>ğŸ’¡<b>{term}ë€? </b></h3>  [ë‹¨ì–´ì— ë§ê²Œ ë€? ë˜ëŠ” ì´ë€?ìœ¼ë¡œ ë³€ê²½í•´ì¤˜.]
        [ë‹¨ì–´ì˜ ì˜ë¯¸ë¥¼ ê°„ê²°í•˜ê³  ëª…í™•í•˜ê²Œ 200ì ë‚´ì™¸ë¡œ ì„¤ëª…í•´ì¤˜.] 

        <h3>ğŸ’š<b>í™œìš© ì˜ˆì‹œ </b></h3>  
        [ë‹¨ì–´ ì´í•´ë¥¼ ë„ì™€ì£¼ëŠ” ê°„ë‹¨í•œ ì˜ˆì‹œë¥¼ ì œì‹œí•´ì¤˜]

        <h3>ğŸ”<b>ì—°ê´€ ë‹¨ì–´</b></h3>
        <ol>
            <li> [ì—°ê´€ë‹¨ì–´1]</li>  
            <li> [ì—°ê´€ë‹¨ì–´2]</li>  
            <li> [ì—°ê´€ë‹¨ì–´3]</li>
        </ol>
        <hr>
        """

        prompt = PromptTemplate(input_variables=["context", "term"], template=template)

        llm = ChatGoogleGenerativeAI(model="gemini-1.5-flash")
        self.chain = (
            {
                "context": retriever | self.format_retriever_output,
                "term": RunnablePassthrough(),
            }
            | prompt
            | llm 
            | StrOutputParser()
        )
    def format_retriever_output(self, docs):
        return "\n".join([doc.page_content for doc in docs])
        
    def invoke(self, user_input):
        return self.chain.invoke(user_input)
    
    def stream(self, user_input):
        return self.chain.stream(user_input)