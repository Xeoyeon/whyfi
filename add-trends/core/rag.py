from .db import db

from langchain.prompts import PromptTemplate
from langchain_core.output_parsers import StrOutputParser
from langchain_core.runnables import RunnablePassthrough
from langchain_google_genai import ChatGoogleGenerativeAI
from dotenv import load_dotenv

load_dotenv()

class RAGAgent:
    def __init__(self):
        retriever = db.vectorstore.as_retriever(search_kwargs={"k": 5})
        template = """
        ë‹¹ì‹ ì€ ê¸ˆìœµ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
        ì‚¬ìš©ìê°€ ì…ë ¥í•œ ê¸ˆìœµ ìš©ì–´ë¥¼ ëˆ„êµ¬ë‚˜ ì´í•´í•˜ê¸° ì‰½ê³  ê°„ë‹¨í•˜ê²Œ ì„¤ëª…í•©ë‹ˆë‹¤. í•„ìš”í•˜ë©´ ì´í•´ë¥¼ ë•ê¸° ìœ„í•œ ì˜ˆì‹œë„ ì„¤ëª…ì— í¬í•¨í•©ë‹ˆë‹¤.
        ê·¸ë¦¬ê³  ê·¸ ìš©ì–´ì™€ ì—°ê´€ëœ ê²€ìƒ‰ì–´ 3ê°œë¥¼ ì œê³µí•©ë‹ˆë‹¤. 

        ê´€ë ¨ ì •ë³´:
        {context}

        ê¸ˆìœµ ìš©ì–´:
        {term}

        ğŸ’¡{term}ë€?: 

        ğŸ”ì—°ê´€ ê²€ìƒ‰ì–´:
        """
        prompt = PromptTemplate(input_variables=["context", "term"], template=template)

        llm = ChatGoogleGenerativeAI(model="gemini-1.5-flash")
        self.chain = (
            {
                "context": retriever | self.format_retriever_output,
                "term": RunnablePassthrough(),
            }
            | prompt
            | llm 
            | StrOutputParser()
        )
    def format_retriever_output(self, docs):
        return "\n".join([doc.page_content for doc in docs])
        
    def invoke(self, user_input):
        return self.chain.invoke(user_input)
    
    def stream(self, user_input):
        return self.chain.stream(user_input)
