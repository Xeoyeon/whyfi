{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "aLIWKW5fzhAT",
        "iJIaFzs3_5JI",
        "YpBVRFsIzsBh",
        "6pcCsbSd0u2r",
        "pydocZFnbP4H",
        "Y29G7jl4F1Tp"
      ],
      "toc_visible": true,
      "gpuType": "T4",
      "authorship_tag": "ABX9TyO5YJb7jkmDmOQ9dp3FX1PL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/4rldur0/whyfi/blob/xeoyeon/RAG.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# colabì—ì„œ ëŒë ¤ë³´ê¸°"
      ],
      "metadata": {
        "id": "cC9rzq7eai-h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. google drive ì—°ë™\n",
        "ë°ì´í„°ì…‹ ê°€ì ¸ì˜¤ê¸°"
      ],
      "metadata": {
        "id": "aLIWKW5fzhAT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tMfHySIj6nnG"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd /content/drive/MyDrive/Colab Notebooks/RAG"
      ],
      "metadata": {
        "id": "UnRtUY0U61M3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers chromadb langchain langchain_community langchain-chroma langchain-huggingface"
      ],
      "metadata": {
        "id": "uRlMWYW28arl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. ì‚¬ìš©í•  dataset embedding, vector db ì„¤ì •\n",
        "- dataset :\n",
        "    - \"í•œêµ­ì€í–‰ ê²½ì œê¸ˆìœµìš©ì–´ 700ì„ .pdf\"=> ë°ì´í„° íŒŒì‹±í•˜ì—¬ csv íŒŒì¼ ì‚¬ìš©(cleaned_word_dict.csv)\n",
        "    - \"2024 í•œê¶Œìœ¼ë¡œ OK ì£¼ì‹ê³¼ ì„¸ê¸ˆ.pdf\"\n",
        "    - \"ì•Œê³  ì‹¶ì–´ìš”? ì£¼ì‹ì‹œì¥.pdf\"\n",
        "- embedding : \"dragonkue/BGE-m3-ko\"\n",
        "- vector DB : chromaDB"
      ],
      "metadata": {
        "id": "iJIaFzs3_5JI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### pdf -> chunk\n"
      ],
      "metadata": {
        "id": "W2Emyy8JEfYC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pymupdf"
      ],
      "metadata": {
        "id": "UObSUamSvqeP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.document_loaders import PyMuPDFLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain_huggingface import HuggingFaceEmbeddings\n",
        "from langchain_chroma import Chroma\n",
        "\n",
        "# 1. ì—¬ëŸ¬ ê°œì˜ PDF íŒŒì¼ ë¡œë“œ\n",
        "pdf_paths = [\"/content/drive/MyDrive/Colab Notebooks/RAG/dataset/[2024 á„’á…¡á†«á„€á…¯á†«á„‹á…³á„…á…© OK á„Œá…®á„‰á…µá†¨á„€á…ª á„‰á…¦á„€á…³á†·].pdf\", \"/content/drive/MyDrive/Colab Notebooks/RAG/dataset/[á„‹á…¡á†¯á„€á…© á„‰á…µá‡á„‹á…¥á„‹á…­ á„Œá…®á„‰á…µá†¨á„‰á…µá„Œá…¡á†¼].pdf\"]  # PDF íŒŒì¼ ë¦¬ìŠ¤íŠ¸\n",
        "documents = []\n",
        "for pdf in pdf_paths:\n",
        "    loader = PyMuPDFLoader(pdf)\n",
        "    documents.extend(loader.load())\n",
        "\n",
        "# 2. í…ìŠ¤íŠ¸ ë¶„í• \n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
        "split_docs = text_splitter.split_documents(documents)\n",
        "\n",
        "# 3. ì„ë² ë”© ëª¨ë¸ ì„¤ì • ë° ì €ì¥\n",
        "embedding =\"dragonkue/BGE-m3-ko\"\n",
        "collection_name = \"Chroma_Collection\"\n",
        "chroma_path = \"/content/drive/MyDrive/Colab Notebooks/RAG\" # ë°ì´í„° ì €ì¥ ê²½ë¡œ\n",
        "\n",
        "# Init chromadb\n",
        "embedding_func = HuggingFaceEmbeddings(model_name=embedding, encode_kwargs={'normalize_embeddings':True},)\n",
        "vectorstore = Chroma(\n",
        "    collection_name,\n",
        "    embedding_function=embedding_func,\n",
        "    persist_directory=chroma_path,\n",
        ")\n",
        "\n",
        "vectorstore.add_documents(split_docs) # vectorstoreì— ì €ì¥"
      ],
      "metadata": {
        "id": "Ww-X-VFtEim9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### csv file"
      ],
      "metadata": {
        "id": "YpBVRFsIzsBh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "file_path = '/content/drive/MyDrive/Colab Notebooks/RAG/dataset/cleaned_word_dict.csv'\n",
        "data = pd.read_csv(file_path)"
      ],
      "metadata": {
        "id": "iPg9guWzFg2B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.docstore.document import Document # ë°ì´í„°ì˜ ê° rowë¥¼ document ê°ì²´ë¡œ ë³€í™˜í•˜ì—¬ ì €ì¥í•˜ê¸° ìœ„í•¨\n",
        "\n",
        "# vectorDBì— data ì¶”ê°€í•˜ëŠ” í•¨ìˆ˜\n",
        "def add_data_to_vectorstore(data, vectorstore):\n",
        "  for index, row in data.iterrows(): # rowë¼ëŠ” ë³€ìˆ˜ì— ê° í–‰ì„ ë°˜ë³µì ìœ¼ë¡œ ê°€ì ¸ì˜´.\n",
        "    text = row.get(\"Content\",\"\")\n",
        "    metadata = row.to_dict() #í–‰ ì „ì²´ë¥¼ ë”•ì…”ë„ˆë¦¬ í˜•íƒœë¡œ ë³€í™˜\n",
        "    metadata[\"source\"] = metadata.get(\"source\", f\"row_{index}\")   # source í•„ë“œ ì¶”ê°€ (ê¸°ë³¸ê°’ìœ¼ë¡œ í–‰ ë²ˆí˜¸ë¥¼ ì‚¬ìš©í•˜ê±°ë‚˜ íŠ¹ì • ì—´ì—ì„œ ê°€ì ¸ì˜¤ê¸°)\n",
        "    document = Document(page_content=text, metadata=metadata) #cocument ê°ì²´ë¥¼ ìƒì„±\n",
        "    vectorstore.add_texts([document.page_content],[document.metadata]) # dbì— ë°ì´í„° ì¶”ê°€\n",
        "\n",
        "add_data_to_vectorstore(data, vectorstore)"
      ],
      "metadata": {
        "id": "6MjvPo_OG4j4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ì „ì— ì„ë² ë”© í•´ë‘” ê²½ìš°"
      ],
      "metadata": {
        "id": "6pcCsbSd0u2r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ê¸°ì¡´ ì„ë² ë”© ê²°ê³¼ë§Œ ê°€ì ¸ì˜¤ê¸°\n",
        "import os\n",
        "from langchain_chroma import Chroma\n",
        "from langchain_huggingface import HuggingFaceEmbeddings\n",
        "\n",
        "embedding =\"dragonkue/BGE-m3-ko\"\n",
        "collection_name = \"Chroma_Collection\"\n",
        "chroma_path = \"/content/drive/MyDrive/Colab Notebooks/RAG\" # ë°ì´í„° ì €ì¥ ê²½ë¡œ\n",
        "\n",
        "# Init chromadb\n",
        "embedding_func = HuggingFaceEmbeddings(model_name=embedding, encode_kwargs={'normalize_embeddings':True},)\n",
        "vectorstore = Chroma(\n",
        "    collection_name,\n",
        "    embedding_function=embedding_func,\n",
        "    persist_directory=chroma_path,\n",
        ")"
      ],
      "metadata": {
        "id": "8q3EifDs_3Nk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Retriever ë° í”„ë¡¬í”„íŠ¸ ì„¤ì •"
      ],
      "metadata": {
        "id": "pydocZFnbP4H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a retriever to search in the vectorstore\n",
        "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 3}) # ê²€ìƒ‰ ì‹œ ê°€ì¥ ê´€ë ¨ì„± ë†’ì€ 3ê°œì˜ ë¬¸ì„œë¥¼ ë°˜í™˜í•˜ë¼ëŠ” ëœ»"
      ],
      "metadata": {
        "id": "z0WAxsuOIonS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.prompts import ChatPromptTemplate, SystemMessagePromptTemplate, HumanMessagePromptTemplate\n",
        "\n",
        "system_template = \"\"\"ë‹¹ì‹ ì€ ê¸ˆìœµ ì „ë¬¸ê°€ë¡œ, ë³µì¡í•œ ê¸ˆìœµ ìš©ì–´ë¥¼ ì‰½ê²Œ ì„¤ëª…í•˜ëŠ” ë° ëŠ¥ìˆ™í•©ë‹ˆë‹¤. ì‚¬ìš©ìê°€ ê¸ˆìœµê³¼ ê´€ë ¨ëœ ìš©ì–´ì— ëŒ€í•´ ì§ˆë¬¸í•˜ë©´, ë‹¤ìŒì„ ìˆ˜í–‰í•˜ì„¸ìš”:\n",
        "\n",
        "Context: {context}\n",
        "\n",
        "Question: {question}\n",
        "\n",
        "Answer:\n",
        "ìš©ì–´ ì„¤ëª…: ì§ˆë¬¸ì— í¬í•¨ëœ ê¸ˆìœµ ìš©ì–´ë¥¼ ê°„ë‹¨í•˜ê³  ëª…í™•í•œ ì–¸ì–´ë¡œ ì„¤ëª…í•˜ì„¸ìš”.\n",
        "ì¶”ê°€ ì •ë³´: ì‚¬ìš©ìê°€ í•´ë‹¹ ê°œë…ì„ ë” ì˜ ì´í•´í•  ìˆ˜ ìˆë„ë¡, ì‹¤ì œ ì‚¬ë¡€ë‚˜ ë¹„ìœ ë¥¼ í¬í•¨í•˜ì—¬ ì„¤ëª…ì„ ë³´ì™„í•˜ì„¸ìš”.\n",
        "ê´€ë ¨ ìš©ì–´: í•´ë‹¹ ìš©ì–´ì™€ ì—°ê´€ëœ ë‹¤ë¥¸ ê¸ˆìœµ ìš©ì–´ë‚˜ ê°œë…ì„ ìµœëŒ€ 3ê°œê¹Œì§€ ì¶”ì²œí•˜ì„¸ìš”.\"\"\"\n",
        "\n",
        "messages = [\n",
        "    SystemMessagePromptTemplate.from_template(system_template),\n",
        "    HumanMessagePromptTemplate.from_template(\"{question}\")\n",
        "]\n",
        "\n",
        "prompt = ChatPromptTemplate.from_messages(messages)"
      ],
      "metadata": {
        "id": "Ry-kcYg3M7ib"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. gemini api ì„¤ì • ë° chain êµ¬í˜„í•˜ê¸°"
      ],
      "metadata": {
        "id": "Y29G7jl4F1Tp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain-google-vertexai"
      ],
      "metadata": {
        "id": "VfkpxLXDTZQI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "PROJECT_ID = \"your_project_id\"\n",
        "REGION = \"your_region\"\n",
        "\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()"
      ],
      "metadata": {
        "id": "rmnNDrjsUCXh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import vertexai\n",
        "from langchain.chains import RetrievalQAWithSourcesChain\n",
        "from langchain_google_vertexai import VertexAI\n",
        "from langchain.prompts import PromptTemplate\n",
        "\n",
        "vertexai.init(project = PROJECT_ID , location = REGION)\n",
        "\n",
        "chain_type_kwargs = {\n",
        "    \"prompt\": prompt,\n",
        "    \"document_variable_name\": \"context\",  # 'context'ê°€ documentsë¥¼ ë°›ì„ ë³€ìˆ˜ì„ì„ ëª…ì‹œ\n",
        "}\n",
        "llm = VertexAI(\n",
        "    temperature=0,\n",
        "    model_name=\"gemini-pro\",\n",
        "    max_output_tokens=1024\n",
        ")\n",
        "\n",
        "chain = RetrievalQAWithSourcesChain.from_chain_type(\n",
        "    llm=llm,\n",
        "    chain_type=\"stuff\",\n",
        "    retriever = retriever,\n",
        "    return_source_documents=True,\n",
        "    chain_type_kwargs=chain_type_kwargs\n",
        ")"
      ],
      "metadata": {
        "id": "UshxPJxgNiU_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Chain ì‚¬ìš© ì˜ˆì‹œ\n",
        "question = \"ê°€ë™ë¥ ì´ë€?\"\n",
        "result = chain({\"question\": question})\n",
        "\n",
        "print(\"Answer:\", result[\"answer\"])\n",
        "print(\"Sources:\", result[\"source_documents\"])"
      ],
      "metadata": {
        "id": "GGimgZgpYGpT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# streamlit\n",
        "1. [ngrok](https://dashboard.ngrok.com/) ì— ì ‘ì† í›„ íšŒì›ê°€ì…\n",
        "2. ë¡œê·¸ì¸ í›„ ëœ¨ëŠ” authtoken ë²ˆí˜¸ë¥¼ ì•„ë˜ì˜ ì½”ë“œì— ë¶™ì—¬ë„£ê¸°\n",
        "3. app.py íŒŒì¼ì„ ìƒì„±í•˜ì—¬ ëŒë¦¬ê¸°\n"
      ],
      "metadata": {
        "id": "h_plpPTTGzhz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain-google-vertexai"
      ],
      "metadata": {
        "id": "DAmxuSLDZsJj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install streamlit\n",
        "!pip install pyngrok"
      ],
      "metadata": {
        "id": "w43K67gkG6QW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "PROJECT_ID = \"your_project_id\"\n",
        "REGION = \"your_region\"\n",
        "\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()"
      ],
      "metadata": {
        "id": "sFqaTfPFi2n2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app.py\n",
        "\n",
        "import streamlit as st\n",
        "import vertexai\n",
        "from langchain.chains import RetrievalQAWithSourcesChain\n",
        "from langchain_google_vertexai import VertexAI\n",
        "from langchain.prompts import PromptTemplate\n",
        "import os\n",
        "from langchain_chroma import Chroma\n",
        "from langchain_huggingface import HuggingFaceEmbeddings\n",
        "from langchain.prompts import ChatPromptTemplate, SystemMessagePromptTemplate, HumanMessagePromptTemplate\n",
        "import re\n",
        "import requests\n",
        "\n",
        "# 1. embedding model ì„¤ì •\n",
        "embedding =\"dragonkue/BGE-m3-ko\"\n",
        "collection_name = \"Chroma_Collection\"\n",
        "chroma_path = \"/content/drive/MyDrive/Colab Notebooks/RAG\" #ë°ì´í„° ì €ì¥ ê²½ë¡œ\n",
        "\n",
        "# 2. vector db ì„¤ì • (chromaDB ì‚¬ìš©)\n",
        "embedding_func = HuggingFaceEmbeddings(model_name=embedding, encode_kwargs={'normalize_embeddings':True},)\n",
        "vectorstore = Chroma(\n",
        "    collection_name,\n",
        "    embedding_function=embedding_func,\n",
        "    persist_directory=chroma_path,\n",
        "    collection_metadata={\"max_size\": 1000}  # ìš©ëŸ‰ ì„¤ì •\n",
        ")\n",
        "\n",
        "# 3. retriever ì„¤ì •\n",
        "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 3})\n",
        "\n",
        "# 4. prompt ì„¤ì •\n",
        "system_template = \"\"\"ë‹¹ì‹ ì€ ê¸ˆìœµ ì „ë¬¸ê°€ë¡œ, ë³µì¡í•œ ê¸ˆìœµ ìš©ì–´ë¥¼ ì‰½ê²Œ ì„¤ëª…í•˜ëŠ” ë° ëŠ¥ìˆ™í•©ë‹ˆë‹¤. ì‚¬ìš©ìê°€ ê¸ˆìœµê³¼ ê´€ë ¨ëœ ìš©ì–´ì— ëŒ€í•´ ì§ˆë¬¸í•˜ë©´, ë‹¤ìŒì„ ìˆ˜í–‰í•˜ì„¸ìš”:\n",
        "\n",
        "Context: {context}\n",
        "\n",
        "Question: {question}\n",
        "\n",
        "Answer:\n",
        "ìš©ì–´ ì„¤ëª…: ì§ˆë¬¸ì— í¬í•¨ëœ ê¸ˆìœµ ìš©ì–´ë¥¼ ê°„ë‹¨í•˜ê³  ëª…í™•í•œ ì–¸ì–´ë¡œ ì„¤ëª…í•˜ì„¸ìš”.\n",
        "ì¶”ê°€ ì •ë³´: ì‚¬ìš©ìê°€ í•´ë‹¹ ê°œë…ì„ ë” ì˜ ì´í•´í•  ìˆ˜ ìˆë„ë¡, ì‹¤ì œ ì‚¬ë¡€ë‚˜ ë¹„ìœ ë¥¼ í¬í•¨í•˜ì—¬ ì„¤ëª…ì„ ë³´ì™„í•˜ì„¸ìš”.\n",
        "ê´€ë ¨ ìš©ì–´: í•´ë‹¹ ìš©ì–´ì™€ ì—°ê´€ëœ ë‹¤ë¥¸ ê¸ˆìœµ ìš©ì–´ë¥¼ ì¶”ì²œí•˜ì„¸ìš”.\n",
        "\n",
        "ë‹¨, ë°˜ë“œì‹œ í•œêµ­ì–´ë¡œ ë‹µë³€í•´ì•¼ í•˜ë©°, ì „ì²´ Answerì˜ ê¸¸ì´ê°€ 8ì¤„ì„ ë„˜ì–´ê°€ì§€ ì•Šë„ë¡ í•˜ì„¸ìš”.\"\"\"\n",
        "\n",
        "messages = [\n",
        "    SystemMessagePromptTemplate.from_template(system_template),\n",
        "    HumanMessagePromptTemplate.from_template(\"{question}\")\n",
        "]\n",
        "\n",
        "prompt = ChatPromptTemplate.from_messages(messages)\n",
        "\n",
        "# 5. LLM ì„¤ì • (gemini ì‚¬ìš©)\n",
        "PROJECT_ID = \"your_project_id\"\n",
        "REGION = \"your_region\"\n",
        "vertexai.init(project = PROJECT_ID , location = REGION)\n",
        "\n",
        "chain_type_kwargs = {\n",
        "    \"prompt\": prompt,\n",
        "    \"document_variable_name\": \"context\",  # 'context'ê°€ documentsë¥¼ ë°›ì„ ë³€ìˆ˜ì„ì„ ëª…ì‹œ\n",
        "}\n",
        "llm = VertexAI(\n",
        "    temperature=0,\n",
        "    model_name=\"gemini-pro\",\n",
        "    max_output_tokens=1024\n",
        ")\n",
        "\n",
        "# 6. ìµœì¢… chain ì„¤ê³„\n",
        "chain = RetrievalQAWithSourcesChain.from_chain_type(\n",
        "    llm=llm,\n",
        "    chain_type=\"stuff\",\n",
        "    retriever = retriever,\n",
        "    return_source_documents=True,\n",
        "    chain_type_kwargs=chain_type_kwargs\n",
        ")\n",
        "\n",
        "# 7. ë„¤ì´ë²„ ë‰´ìŠ¤ API\n",
        "CLIENT_ID=\"satq5UZoVM2fiHsCHrvy\"\n",
        "CLIENT_SECRET=\"Gj_rU32L3v\"\n",
        "\n",
        "def get_naver_news(query, display=5):\n",
        "    url = \"https://openapi.naver.com/v1/search/news.json\"\n",
        "    headers = {\n",
        "        \"X-Naver-Client-Id\": CLIENT_ID,\n",
        "        \"X-Naver-Client-Secret\": CLIENT_SECRET,\n",
        "    }\n",
        "    params = {\n",
        "        \"query\": query,\n",
        "        \"display\": display,\n",
        "        \"sort\": \"sim\"  # ìœ ì‚¬ë„ ê¸°ì¤€ ì •ë ¬\n",
        "    }\n",
        "\n",
        "    response = requests.get(url, headers=headers, params=params)\n",
        "\n",
        "    if response.status_code == 200:\n",
        "        news_items = response.json().get('items', [])\n",
        "        return news_items[:3]  # ìœ ì‚¬ë„ê°€ ë†’ì€ 3ê°œ ë‰´ìŠ¤ë§Œ ë°˜í™˜\n",
        "    else:\n",
        "        return []\n",
        "\n",
        "###### streamlit ì„¤ê³„ #######\n",
        "st.set_page_config(page_title=\"ê¸ˆìœµìš©ì–´ì•Œë¦¬ë¯¸ : WhyFi\")\n",
        "\n",
        "st.markdown(\n",
        "    \"\"\"\n",
        "    <h1 style='color: white; text-align: center;'>ê¸ˆìœµìš©ì–´ì•Œë¦¬ë¯¸ : WhyFi</h1>\n",
        "    <h2 style='color: gray; text-align: center; font-size: 20px;'>ëª¨ë¥´ëŠ” ê¸ˆìœµ ìš©ì–´? ì´ì œ ì‰½ê²Œ ì°¾ì•„ë³´ì„¸ìš”!</h2>\n",
        "    <br>\n",
        "    \"\"\",\n",
        "    unsafe_allow_html=True,\n",
        ")\n",
        "\n",
        "\n",
        "user_question = st.text_input(\"ê¸ˆìœµ ìš©ì–´ë¥¼ ê²€ìƒ‰í•´ë³´ì„¸ìš”.\", value=\"\", placeholder=\"ì˜ˆ: ê°€ë™ë¥ ì´ë€?\")\n",
        "if user_question:\n",
        "    with st.spinner(\"ë‹µë³€ì„ ìƒì„± ì¤‘ì…ë‹ˆë‹¤...\"):\n",
        "        result = chain({\"question\": user_question})\n",
        "\n",
        "    # ê²°ê³¼ ì¶œë ¥\n",
        "    st.markdown(\"#### ğŸ“– ë‹µë³€ ğŸ“–\")\n",
        "    answer_text = result[\"answer\"]\n",
        "    st.write(answer_text)\n",
        "\n",
        "\n",
        "    st.markdown(\"### ğŸ“š ì°¸ê³  ì¶œì²˜ ğŸ“š\")\n",
        "    for doc in result[\"source_documents\"]:\n",
        "        st.markdown(\n",
        "            f\"<div style='font-size:14px; line-height:1.4;'>- {doc.metadata['source']}</div>\",\n",
        "            unsafe_allow_html=True,\n",
        "        )\n",
        "    st.write(\"\")\n",
        "    st.markdown(\"#### ğŸ“° ê´€ë ¨ ë‰´ìŠ¤ ğŸ“°\")\n",
        "    news_results = get_naver_news(user_question)\n",
        "\n",
        "    if news_results:\n",
        "        for news in news_results:\n",
        "            title = news['title'].replace(\"<b>\", \"\").replace(\"</b>\", \"\")\n",
        "            link = news['link']\n",
        "            st.markdown(f\"ğŸ”— [{title}]({link})\", unsafe_allow_html=True)\n"
      ],
      "metadata": {
        "id": "e7UsYrFsHywm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "id": "pl-xgaD2KBrR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# streamlit ì ‘ì†í•˜ê¸° ë° ì—°ê²° í•´ì œ"
      ],
      "metadata": {
        "id": "cR31kn22xMo6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#ê°œì¸ í† í° ë²ˆí˜¸ ì…ë ¥\n",
        "!ngrok authtoken [í† í°ê°’]"
      ],
      "metadata": {
        "id": "bifsVLSMKsFT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyngrok import ngrok\n",
        "!streamlit run app.py&>/dev/null&"
      ],
      "metadata": {
        "id": "CBFpB947KO7D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "publ_url = ngrok.connect(addr=\"8501\")"
      ],
      "metadata": {
        "id": "xwHClxWMKX7w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "publ_url"
      ],
      "metadata": {
        "id": "pE4A6SZdKcmz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ps"
      ],
      "metadata": {
        "id": "A9KYjg9iKmLI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!kill [PID]"
      ],
      "metadata": {
        "id": "ss7eHUUKKkFM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ngrok.kill()"
      ],
      "metadata": {
        "id": "NQPKytE6KnIk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}