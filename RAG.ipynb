{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "aLIWKW5fzhAT",
        "iJIaFzs3_5JI",
        "YpBVRFsIzsBh",
        "6pcCsbSd0u2r",
        "pydocZFnbP4H",
        "Y29G7jl4F1Tp"
      ],
      "toc_visible": true,
      "gpuType": "T4",
      "authorship_tag": "ABX9TyO5YJb7jkmDmOQ9dp3FX1PL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/4rldur0/whyfi/blob/xeoyeon/RAG.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# colab에서 돌려보기"
      ],
      "metadata": {
        "id": "cC9rzq7eai-h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. google drive 연동\n",
        "데이터셋 가져오기"
      ],
      "metadata": {
        "id": "aLIWKW5fzhAT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tMfHySIj6nnG"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd /content/drive/MyDrive/Colab Notebooks/RAG"
      ],
      "metadata": {
        "id": "UnRtUY0U61M3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers chromadb langchain langchain_community langchain-chroma langchain-huggingface"
      ],
      "metadata": {
        "id": "uRlMWYW28arl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. 사용할 dataset embedding, vector db 설정\n",
        "- dataset :\n",
        "    - \"한국은행 경제금융용어 700선.pdf\"=> 데이터 파싱하여 csv 파일 사용(cleaned_word_dict.csv)\n",
        "    - \"2024 한권으로 OK 주식과 세금.pdf\"\n",
        "    - \"알고 싶어요? 주식시장.pdf\"\n",
        "- embedding : \"dragonkue/BGE-m3-ko\"\n",
        "- vector DB : chromaDB"
      ],
      "metadata": {
        "id": "iJIaFzs3_5JI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### pdf -> chunk\n"
      ],
      "metadata": {
        "id": "W2Emyy8JEfYC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pymupdf"
      ],
      "metadata": {
        "id": "UObSUamSvqeP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.document_loaders import PyMuPDFLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain_huggingface import HuggingFaceEmbeddings\n",
        "from langchain_chroma import Chroma\n",
        "\n",
        "# 1. 여러 개의 PDF 파일 로드\n",
        "pdf_paths = [\"/content/drive/MyDrive/Colab Notebooks/RAG/dataset/[2024 한권으로 OK 주식과 세금].pdf\", \"/content/drive/MyDrive/Colab Notebooks/RAG/dataset/[알고 싶어요 주식시장].pdf\"]  # PDF 파일 리스트\n",
        "documents = []\n",
        "for pdf in pdf_paths:\n",
        "    loader = PyMuPDFLoader(pdf)\n",
        "    documents.extend(loader.load())\n",
        "\n",
        "# 2. 텍스트 분할\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
        "split_docs = text_splitter.split_documents(documents)\n",
        "\n",
        "# 3. 임베딩 모델 설정 및 저장\n",
        "embedding =\"dragonkue/BGE-m3-ko\"\n",
        "collection_name = \"Chroma_Collection\"\n",
        "chroma_path = \"/content/drive/MyDrive/Colab Notebooks/RAG\" # 데이터 저장 경로\n",
        "\n",
        "# Init chromadb\n",
        "embedding_func = HuggingFaceEmbeddings(model_name=embedding, encode_kwargs={'normalize_embeddings':True},)\n",
        "vectorstore = Chroma(\n",
        "    collection_name,\n",
        "    embedding_function=embedding_func,\n",
        "    persist_directory=chroma_path,\n",
        ")\n",
        "\n",
        "vectorstore.add_documents(split_docs) # vectorstore에 저장"
      ],
      "metadata": {
        "id": "Ww-X-VFtEim9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### csv file"
      ],
      "metadata": {
        "id": "YpBVRFsIzsBh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "file_path = '/content/drive/MyDrive/Colab Notebooks/RAG/dataset/cleaned_word_dict.csv'\n",
        "data = pd.read_csv(file_path)"
      ],
      "metadata": {
        "id": "iPg9guWzFg2B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.docstore.document import Document # 데이터의 각 row를 document 객체로 변환하여 저장하기 위함\n",
        "\n",
        "# vectorDB에 data 추가하는 함수\n",
        "def add_data_to_vectorstore(data, vectorstore):\n",
        "  for index, row in data.iterrows(): # row라는 변수에 각 행을 반복적으로 가져옴.\n",
        "    text = row.get(\"Content\",\"\")\n",
        "    metadata = row.to_dict() #행 전체를 딕셔너리 형태로 변환\n",
        "    metadata[\"source\"] = metadata.get(\"source\", f\"row_{index}\")   # source 필드 추가 (기본값으로 행 번호를 사용하거나 특정 열에서 가져오기)\n",
        "    document = Document(page_content=text, metadata=metadata) #cocument 객체를 생성\n",
        "    vectorstore.add_texts([document.page_content],[document.metadata]) # db에 데이터 추가\n",
        "\n",
        "add_data_to_vectorstore(data, vectorstore)"
      ],
      "metadata": {
        "id": "6MjvPo_OG4j4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 전에 임베딩 해둔 경우"
      ],
      "metadata": {
        "id": "6pcCsbSd0u2r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 기존 임베딩 결과만 가져오기\n",
        "import os\n",
        "from langchain_chroma import Chroma\n",
        "from langchain_huggingface import HuggingFaceEmbeddings\n",
        "\n",
        "embedding =\"dragonkue/BGE-m3-ko\"\n",
        "collection_name = \"Chroma_Collection\"\n",
        "chroma_path = \"/content/drive/MyDrive/Colab Notebooks/RAG\" # 데이터 저장 경로\n",
        "\n",
        "# Init chromadb\n",
        "embedding_func = HuggingFaceEmbeddings(model_name=embedding, encode_kwargs={'normalize_embeddings':True},)\n",
        "vectorstore = Chroma(\n",
        "    collection_name,\n",
        "    embedding_function=embedding_func,\n",
        "    persist_directory=chroma_path,\n",
        ")"
      ],
      "metadata": {
        "id": "8q3EifDs_3Nk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Retriever 및 프롬프트 설정"
      ],
      "metadata": {
        "id": "pydocZFnbP4H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a retriever to search in the vectorstore\n",
        "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 3}) # 검색 시 가장 관련성 높은 3개의 문서를 반환하라는 뜻"
      ],
      "metadata": {
        "id": "z0WAxsuOIonS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.prompts import ChatPromptTemplate, SystemMessagePromptTemplate, HumanMessagePromptTemplate\n",
        "\n",
        "system_template = \"\"\"당신은 금융 전문가로, 복잡한 금융 용어를 쉽게 설명하는 데 능숙합니다. 사용자가 금융과 관련된 용어에 대해 질문하면, 다음을 수행하세요:\n",
        "\n",
        "Context: {context}\n",
        "\n",
        "Question: {question}\n",
        "\n",
        "Answer:\n",
        "용어 설명: 질문에 포함된 금융 용어를 간단하고 명확한 언어로 설명하세요.\n",
        "추가 정보: 사용자가 해당 개념을 더 잘 이해할 수 있도록, 실제 사례나 비유를 포함하여 설명을 보완하세요.\n",
        "관련 용어: 해당 용어와 연관된 다른 금융 용어나 개념을 최대 3개까지 추천하세요.\"\"\"\n",
        "\n",
        "messages = [\n",
        "    SystemMessagePromptTemplate.from_template(system_template),\n",
        "    HumanMessagePromptTemplate.from_template(\"{question}\")\n",
        "]\n",
        "\n",
        "prompt = ChatPromptTemplate.from_messages(messages)"
      ],
      "metadata": {
        "id": "Ry-kcYg3M7ib"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. gemini api 설정 및 chain 구현하기"
      ],
      "metadata": {
        "id": "Y29G7jl4F1Tp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain-google-vertexai"
      ],
      "metadata": {
        "id": "VfkpxLXDTZQI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "PROJECT_ID = \"your_project_id\"\n",
        "REGION = \"your_region\"\n",
        "\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()"
      ],
      "metadata": {
        "id": "rmnNDrjsUCXh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import vertexai\n",
        "from langchain.chains import RetrievalQAWithSourcesChain\n",
        "from langchain_google_vertexai import VertexAI\n",
        "from langchain.prompts import PromptTemplate\n",
        "\n",
        "vertexai.init(project = PROJECT_ID , location = REGION)\n",
        "\n",
        "chain_type_kwargs = {\n",
        "    \"prompt\": prompt,\n",
        "    \"document_variable_name\": \"context\",  # 'context'가 documents를 받을 변수임을 명시\n",
        "}\n",
        "llm = VertexAI(\n",
        "    temperature=0,\n",
        "    model_name=\"gemini-pro\",\n",
        "    max_output_tokens=1024\n",
        ")\n",
        "\n",
        "chain = RetrievalQAWithSourcesChain.from_chain_type(\n",
        "    llm=llm,\n",
        "    chain_type=\"stuff\",\n",
        "    retriever = retriever,\n",
        "    return_source_documents=True,\n",
        "    chain_type_kwargs=chain_type_kwargs\n",
        ")"
      ],
      "metadata": {
        "id": "UshxPJxgNiU_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Chain 사용 예시\n",
        "question = \"가동률이란?\"\n",
        "result = chain({\"question\": question})\n",
        "\n",
        "print(\"Answer:\", result[\"answer\"])\n",
        "print(\"Sources:\", result[\"source_documents\"])"
      ],
      "metadata": {
        "id": "GGimgZgpYGpT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# streamlit\n",
        "1. [ngrok](https://dashboard.ngrok.com/) 에 접속 후 회원가입\n",
        "2. 로그인 후 뜨는 authtoken 번호를 아래의 코드에 붙여넣기\n",
        "3. app.py 파일을 생성하여 돌리기\n"
      ],
      "metadata": {
        "id": "h_plpPTTGzhz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain-google-vertexai"
      ],
      "metadata": {
        "id": "DAmxuSLDZsJj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install streamlit\n",
        "!pip install pyngrok"
      ],
      "metadata": {
        "id": "w43K67gkG6QW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "PROJECT_ID = \"your_project_id\"\n",
        "REGION = \"your_region\"\n",
        "\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()"
      ],
      "metadata": {
        "id": "sFqaTfPFi2n2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app.py\n",
        "\n",
        "import streamlit as st\n",
        "import vertexai\n",
        "from langchain.chains import RetrievalQAWithSourcesChain\n",
        "from langchain_google_vertexai import VertexAI\n",
        "from langchain.prompts import PromptTemplate\n",
        "import os\n",
        "from langchain_chroma import Chroma\n",
        "from langchain_huggingface import HuggingFaceEmbeddings\n",
        "from langchain.prompts import ChatPromptTemplate, SystemMessagePromptTemplate, HumanMessagePromptTemplate\n",
        "import re\n",
        "import requests\n",
        "\n",
        "# 1. embedding model 설정\n",
        "embedding =\"dragonkue/BGE-m3-ko\"\n",
        "collection_name = \"Chroma_Collection\"\n",
        "chroma_path = \"/content/drive/MyDrive/Colab Notebooks/RAG\" #데이터 저장 경로\n",
        "\n",
        "# 2. vector db 설정 (chromaDB 사용)\n",
        "embedding_func = HuggingFaceEmbeddings(model_name=embedding, encode_kwargs={'normalize_embeddings':True},)\n",
        "vectorstore = Chroma(\n",
        "    collection_name,\n",
        "    embedding_function=embedding_func,\n",
        "    persist_directory=chroma_path,\n",
        "    collection_metadata={\"max_size\": 1000}  # 용량 설정\n",
        ")\n",
        "\n",
        "# 3. retriever 설정\n",
        "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 3})\n",
        "\n",
        "# 4. prompt 설정\n",
        "system_template = \"\"\"당신은 금융 전문가로, 복잡한 금융 용어를 쉽게 설명하는 데 능숙합니다. 사용자가 금융과 관련된 용어에 대해 질문하면, 다음을 수행하세요:\n",
        "\n",
        "Context: {context}\n",
        "\n",
        "Question: {question}\n",
        "\n",
        "Answer:\n",
        "용어 설명: 질문에 포함된 금융 용어를 간단하고 명확한 언어로 설명하세요.\n",
        "추가 정보: 사용자가 해당 개념을 더 잘 이해할 수 있도록, 실제 사례나 비유를 포함하여 설명을 보완하세요.\n",
        "관련 용어: 해당 용어와 연관된 다른 금융 용어를 추천하세요.\n",
        "\n",
        "단, 반드시 한국어로 답변해야 하며, 전체 Answer의 길이가 8줄을 넘어가지 않도록 하세요.\"\"\"\n",
        "\n",
        "messages = [\n",
        "    SystemMessagePromptTemplate.from_template(system_template),\n",
        "    HumanMessagePromptTemplate.from_template(\"{question}\")\n",
        "]\n",
        "\n",
        "prompt = ChatPromptTemplate.from_messages(messages)\n",
        "\n",
        "# 5. LLM 설정 (gemini 사용)\n",
        "PROJECT_ID = \"your_project_id\"\n",
        "REGION = \"your_region\"\n",
        "vertexai.init(project = PROJECT_ID , location = REGION)\n",
        "\n",
        "chain_type_kwargs = {\n",
        "    \"prompt\": prompt,\n",
        "    \"document_variable_name\": \"context\",  # 'context'가 documents를 받을 변수임을 명시\n",
        "}\n",
        "llm = VertexAI(\n",
        "    temperature=0,\n",
        "    model_name=\"gemini-pro\",\n",
        "    max_output_tokens=1024\n",
        ")\n",
        "\n",
        "# 6. 최종 chain 설계\n",
        "chain = RetrievalQAWithSourcesChain.from_chain_type(\n",
        "    llm=llm,\n",
        "    chain_type=\"stuff\",\n",
        "    retriever = retriever,\n",
        "    return_source_documents=True,\n",
        "    chain_type_kwargs=chain_type_kwargs\n",
        ")\n",
        "\n",
        "# 7. 네이버 뉴스 API\n",
        "CLIENT_ID=\"satq5UZoVM2fiHsCHrvy\"\n",
        "CLIENT_SECRET=\"Gj_rU32L3v\"\n",
        "\n",
        "def get_naver_news(query, display=5):\n",
        "    url = \"https://openapi.naver.com/v1/search/news.json\"\n",
        "    headers = {\n",
        "        \"X-Naver-Client-Id\": CLIENT_ID,\n",
        "        \"X-Naver-Client-Secret\": CLIENT_SECRET,\n",
        "    }\n",
        "    params = {\n",
        "        \"query\": query,\n",
        "        \"display\": display,\n",
        "        \"sort\": \"sim\"  # 유사도 기준 정렬\n",
        "    }\n",
        "\n",
        "    response = requests.get(url, headers=headers, params=params)\n",
        "\n",
        "    if response.status_code == 200:\n",
        "        news_items = response.json().get('items', [])\n",
        "        return news_items[:3]  # 유사도가 높은 3개 뉴스만 반환\n",
        "    else:\n",
        "        return []\n",
        "\n",
        "###### streamlit 설계 #######\n",
        "st.set_page_config(page_title=\"금융용어알리미 : WhyFi\")\n",
        "\n",
        "st.markdown(\n",
        "    \"\"\"\n",
        "    <h1 style='color: white; text-align: center;'>금융용어알리미 : WhyFi</h1>\n",
        "    <h2 style='color: gray; text-align: center; font-size: 20px;'>모르는 금융 용어? 이제 쉽게 찾아보세요!</h2>\n",
        "    <br>\n",
        "    \"\"\",\n",
        "    unsafe_allow_html=True,\n",
        ")\n",
        "\n",
        "\n",
        "user_question = st.text_input(\"금융 용어를 검색해보세요.\", value=\"\", placeholder=\"예: 가동률이란?\")\n",
        "if user_question:\n",
        "    with st.spinner(\"답변을 생성 중입니다...\"):\n",
        "        result = chain({\"question\": user_question})\n",
        "\n",
        "    # 결과 출력\n",
        "    st.markdown(\"#### 📖 답변 📖\")\n",
        "    answer_text = result[\"answer\"]\n",
        "    st.write(answer_text)\n",
        "\n",
        "\n",
        "    st.markdown(\"### 📚 참고 출처 📚\")\n",
        "    for doc in result[\"source_documents\"]:\n",
        "        st.markdown(\n",
        "            f\"<div style='font-size:14px; line-height:1.4;'>- {doc.metadata['source']}</div>\",\n",
        "            unsafe_allow_html=True,\n",
        "        )\n",
        "    st.write(\"\")\n",
        "    st.markdown(\"#### 📰 관련 뉴스 📰\")\n",
        "    news_results = get_naver_news(user_question)\n",
        "\n",
        "    if news_results:\n",
        "        for news in news_results:\n",
        "            title = news['title'].replace(\"<b>\", \"\").replace(\"</b>\", \"\")\n",
        "            link = news['link']\n",
        "            st.markdown(f\"🔗 [{title}]({link})\", unsafe_allow_html=True)\n"
      ],
      "metadata": {
        "id": "e7UsYrFsHywm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "id": "pl-xgaD2KBrR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# streamlit 접속하기 및 연결 해제"
      ],
      "metadata": {
        "id": "cR31kn22xMo6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#개인 토큰 번호 입력\n",
        "!ngrok authtoken [토큰값]"
      ],
      "metadata": {
        "id": "bifsVLSMKsFT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyngrok import ngrok\n",
        "!streamlit run app.py&>/dev/null&"
      ],
      "metadata": {
        "id": "CBFpB947KO7D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "publ_url = ngrok.connect(addr=\"8501\")"
      ],
      "metadata": {
        "id": "xwHClxWMKX7w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "publ_url"
      ],
      "metadata": {
        "id": "pE4A6SZdKcmz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ps"
      ],
      "metadata": {
        "id": "A9KYjg9iKmLI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!kill [PID]"
      ],
      "metadata": {
        "id": "ss7eHUUKKkFM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ngrok.kill()"
      ],
      "metadata": {
        "id": "NQPKytE6KnIk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}