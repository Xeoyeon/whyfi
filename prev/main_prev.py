from langchain_google_genai import ChatGoogleGenerativeAI
from langchain.prompts import PromptTemplate
from langchain_core.output_parsers import StrOutputParser
from langchain_core.runnables import RunnablePassthrough
from langchain_chroma import Chroma
from langchain_core.documents import Document
from langchain_huggingface import HuggingFaceEmbeddings
from langchain_community.document_loaders.csv_loader import CSVLoader
from langchain.document_loaders import PyPDFLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter

import os
import google.generativeai as genai
import requests
import streamlit as st
import random

from dotenv import load_dotenv
load_dotenv()
os.chdir('C:\\Users\\seoyounglee\\workspace\\Euron\\Whyfi')

from pop_words import KeywordCrawler, save_keywords_to_file, load_keywords_from_file
keywords_data = load_keywords_from_file()

if keywords_data is None:
    print("ë°ì´í„°ê°€ ì—†ìœ¼ë¯€ë¡œ í¬ë¡¬ ë“œë¼ì´ë²„ë¥¼ ì´ˆê¸°í™”í•˜ê³  í¬ë¡¤ë§ì„ ì‹œì‘í•©ë‹ˆë‹¤.")
    url = 'https://eiec.kdi.re.kr/bigdata/issueTrend.do'
    crawler = KeywordCrawler(url)
    crawler.initialize_driver()
    keywords = crawler.get_keywords()
    crawler.close_driver()
    save_keywords_to_file(keywords)  
    keywords_data = load_keywords_from_file()


keywords = keywords_data["keywords"]
date = keywords_data["date"]

if 'user_input' not in st.session_state: st.session_state.user_input = '' 

def show_keywords_in_sidebar(data,date):
    st.sidebar.markdown(f'<h4 style="font-size: 16px;">ğŸ“Š ê¸ˆìœµ í‚¤ì›Œë“œ ìˆœìœ„ ({date})</h4>', unsafe_allow_html=True)    
    number_to_unicode = {
    1: "â‘ ", 2: "â‘¡", 3: "â‘¢", 4: "â‘£", 5: "â‘¤", 6: "â‘¥", 7: "â‘¦", 8: "â‘§", 9: "â‘¨", 10: "â‘©"
    }
    for i, keyword in enumerate(data):
        if keyword != "NEW":
            #st.sidebar.write(f"{i + 1}. {keyword}")
            if st.sidebar.button(f"{number_to_unicode.get(i + 1, i + 1)} {keyword}"):
                # ë²„íŠ¼ í´ë¦­ ì‹œ user_inputì— í•´ë‹¹ í‚¤ì›Œë“œë¥¼ ì €ì¥
                st.session_state.user_input = keyword  # ì„¸ì…˜ ìƒíƒœì— í‚¤ì›Œë“œë¥¼ ì €ì¥
                st.rerun()
    
    st.sidebar.markdown(f'<p style="font-size: 14px;color: #555;">&copy; KDI ê²½ì œêµìœ¡Â·ì •ë³´ì„¼í„° ê²½ì œ í‚¤ì›Œë“œ íŠ¸ë Œë“œ</p>', unsafe_allow_html=True)


embedding_model = HuggingFaceEmbeddings(
                model_name="dragonkue/BGE-m3-ko",
                multi_process=False,
                model_kwargs={"device": "cpu"},
                encode_kwargs={"normalize_embeddings": True},  
                # Set `True` for cosine similarity
            )

vector_store = Chroma(
    persist_directory="chroma_db", embedding_function=embedding_model
    ) 

#retriever = emb.as_retriever(search_kwargs={"k": 5})
retriever = vector_store.as_retriever(search_kwargs={"k": 5})

genai.configure(api_key=os.getenv("GOOGLE_API_KEY"))
llm = ChatGoogleGenerativeAI(model="gemini-1.5-flash", temperature=0.5)

def news_srch(query):
    try:
        client_id = os.getenv("NAVER_CLIENT_ID")
        client_secret = os.getenv("NAVER_CLIENT_SECRET")
        url = f"https://openapi.naver.com/v1/search/news.json?query={query}&display=20&sort=sim"
        headers = {
            "X-Naver-Client-Id": client_id,
            "X-Naver-Client-Secret": client_secret,
        }
        response = requests.get(url, headers=headers)
        response.raise_for_status()  # ì˜¤ë¥˜ ë°œìƒ ì‹œ ì˜ˆì™¸ ì²˜ë¦¬

        if response.status_code == 200:
            news_items = response.json().get("items", [])

            if not news_items:
                return "âŒ ê´€ë ¨ ë‰´ìŠ¤ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."


        random_news = random.sample(news_items, min(5, len(news_items)))
        return "\n".join([f"- [{item['title']}]({item['link']})" for item in random_news])

    except requests.exceptions.RequestException as e:
        return f"ğŸš¨ ë„¤ì´ë²„ ë‰´ìŠ¤ API ìš”ì²­ ì‹¤íŒ¨: {e}"

template = '''
ë„ˆëŠ” ì…ë ¥ëœ ê¸ˆìœµ ë¶„ì•¼ ë‹¨ì–´ë¥¼ ì‰½ê³ , ì¼ìƒì ì¸ ì–¸ì–´ë¡œ ì„¤ëª…í•´ì£¼ëŠ” ì±—ë´‡ ì–´ì‹œìŠ¤í„´íŠ¸ì•¼.
ê¸ˆìœµ ì§€ì‹ì´ ë¶€ì¡±í•œ ì‚¬ëŒë“¤ë„ ì‰½ê²Œ ì´í•´í•  ìˆ˜ ìˆê²Œ ì„¤ëª…í•´ì¤˜. ëª¨ë“  ëŒ€ë‹µì€ í•œêµ­ì–´ë¡œ í•´ì£¼ê³ ,
ì–´ë ¤ìš´ ë‹¨ì–´ëŠ” ìµœëŒ€í•œ í’€ì–´ì„œ ë§í•´ì¤˜. ë¬¸ì¥ì€ ì¹œê·¼í•œ êµ¬ì–´ì²´ë¡œ ëë‚´ëŠ” ê²Œ ì¢‹ì•„.

ë‹¨ì–´ì˜ ì˜ë¯¸, í™œìš© ì˜ˆì‹œ, ì—°ê´€ëœ ë‹¨ì–´ 3ê°œë¥¼ ì œê³µí•´ì•¼ í•´. í˜•ì‹ì€ ì•„ë˜ì™€ ê°™ì•„:

ê²€ìƒ‰ì–´ : [ë‹¨ì–´]  

ì •ì˜ : [ë‹¨ì–´ì˜ ì˜ë¯¸ë¥¼ ê°„ê²°í•˜ê³  ëª…í™•í•˜ê²Œ ì„¤ëª…í•´ì¤˜, 200ì ì´í•˜ë¡œ, ì„¤ëª… ëë§ˆë‹¤ ì¤„ë°”ê¿ˆì„ ì¶”ê°€í•´ì„œ ì½ê¸° ì‰½ê²Œ í•´ì¤˜] 
í™œìš© ì˜ˆì‹œ : [ë‹¨ì–´ë¥¼ ìì—°ìŠ¤ëŸ½ê²Œ í¬í•¨í•œ ë¬¸ì¥ ì˜ˆì‹œ]  
ì—°ê´€ ë‹¨ì–´ : [ë‹¨ì–´ì™€ ê´€ë ¨ ìˆëŠ” ë‹¤ë¥¸ ë‹¨ì–´ 3ê°œë¥¼ ì‰¼í‘œë¡œ êµ¬ë¶„í•´ì„œ ë‚˜ì—´]  

Question: {question}
'''

prompt = PromptTemplate(
    input_variables=["question"], 
    template=template
)

def format_retriever_output(docs):
    return "\n".join([doc.page_content for doc in docs])

chain = (
    {
        "context": retriever,
        "question": RunnablePassthrough(),
    }
    | prompt
    | llm 
    | StrOutputParser()
)



#ì‚¬ì´ë“œë°”
st.set_page_config(page_title="WhyFi by Euron", page_icon="ğŸ’°", layout="wide")
st.sidebar.title("ğŸ“Œ ê¶ê¸ˆí•œ ê¸ˆìœµ ìš©ì–´ë¥¼ ì…ë ¥í•˜ì„¸ìš”! ")

# ì‚¬ì´ë“œë°”ì— í‚¤ì›Œë“œ ìˆœìœ„ ì¶œë ¥
user_input = st.sidebar.text_input("ì˜ˆ: ë³µë¦¬, ì£¼ì‹, ETF ë“±", value=st.session_state.user_input)
show_keywords_in_sidebar(keywords,date)

st.markdown("""
# ğŸ’° **WhyFi** : ê¸ˆìœµ ìš©ì–´ ì•Œë¦¬ë¯¸
**WhyFi**ëŠ” **ì–´ë ¤ìš´ ê¸ˆìœµì´ë¼ëŠ” ì£¼ì œë¥¼ ì‰½ê²Œ ì „ë‹¬í•˜ê³ ì ê°œë°œëœ ì„œë¹„ìŠ¤**ì…ë‹ˆë‹¤.
ë³µì¡í•œ ê¸ˆìœµ ìš©ì–´ë¥¼ ì¼ìƒì ì¸ ì–¸ì–´ë¡œ ì„¤ëª…í•˜ë©°, ê´€ë ¨ëœ ìµœì‹  ë‰´ìŠ¤ ì •ë³´ë¥¼ ì œê³µí•©ë‹ˆë‹¤.
ì´ë¥¼ í†µí•´ ê¸ˆìœµ ì§€ì‹ì— ëŒ€í•œ ì´í•´ë„ë¥¼ ë†’ì´ê³ , ë” ë‚˜ì€ ê¸ˆìœµ ê²°ì •ì„ ë‚´ë¦´ ìˆ˜ ìˆë„ë¡ ë•ëŠ” ê²ƒì„ ëª©í‘œë¡œ í•©ë‹ˆë‹¤.

ğŸ“Œ **ì£¼ìš” ê¸°ëŠ¥** \n
â–ªï¸ ì‚¬ìš©ìê°€ ì§ì ‘ ì…ë ¥í•œ ê¸ˆìœµ ìš©ì–´ì— ëŒ€í•œ ë§ì¶¤í˜• ë‹µë³€ ì œê³µ \n
â–ªï¸ ê¸ˆìœµ ìš©ì–´ì— ëŒ€í•œ ì‰¬ìš´ ì„¤ëª… ì œê³µ \n
â–ªï¸ ê´€ë ¨ ë‰´ìŠ¤ì™€ ìµœì‹  íŠ¸ë Œë“œ ì •ë³´ ì œê³µ \n

ì™€ì´íŒŒì´ì™€ í•¨ê»˜ ê¸ˆìœµì„ ì‰½ê²Œ ì´í•´í•˜ê³ , ìŠ¤ë§ˆíŠ¸í•œ ê¸ˆìœµ ë¦¬í„°ëŸ¬ì‹œë¥¼ ìŒ“ì•„ ë³´ì„¸ìš”!
""")

if user_input:
    with st.spinner("ğŸ”„ ì •ë³´ë¥¼ ë¶„ì„í•˜ëŠ” ì¤‘..."):
        news_results = news_srch(user_input)
        retrieved_docs = retriever.invoke(user_input)
        response = chain.invoke(user_input)

    st.success(f"â“{response}")  # ê°•ì¡° íš¨ê³¼

    st.subheader("ğŸ“° ê´€ë ¨ ë‰´ìŠ¤")
    if "âŒ ê´€ë ¨ ë‰´ìŠ¤ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤." in news_results:
        st.warning("âŒ í˜„ì¬ ê´€ë ¨ëœ ë‰´ìŠ¤ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë‹¤ë¥¸ ìš©ì–´ë¥¼ ê²€ìƒ‰í•´ ë³´ì„¸ìš”!")
    else:
        for news in news_results.split("\n"):
            #st.markdown(f"[{item['title']}]({item['link']})")
            st.markdown(news, unsafe_allow_html=True)

st.markdown("""
---
<footer style="text-align: right; padding: 10px; font-size: 14px; color: #555;">
    <p>&copy; Euron Research 7th WhyFi íŒ€. All rights reserved.</p>
    <p>ver 1.0 | Last modified 25.02.02</p>
</footer>
""", unsafe_allow_html=True)

#streamlit run c:/Users/seoyounglee/workspace/Euron/Whyfi/main.py
#git clone https://github.com/4rldur0/whyfi.git
# cd whyfi
# streamlit run streamlit.py
# python app.py